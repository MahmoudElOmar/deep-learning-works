{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Using Deep Learning on MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, n = 10):\n",
    "    one_hot = []\n",
    "    for i in range(len(Y)):\n",
    "        current = np.zeros((n,1))\n",
    "        current[Y[i]] = 1\n",
    "        one_hot.append(current)\n",
    "    return one_hot\n",
    "def load_data(filePath):\n",
    "    Y = []\n",
    "    X = []\n",
    "    with open(filePath) as csv_file:\n",
    "        readData = csv.reader(csv_file, delimiter = ',')\n",
    "        next(readData)\n",
    "        for row in readData:\n",
    "            if filePath == \"train.csv\":\n",
    "                Y.append(int(row[0]))\n",
    "                del row[0]\n",
    "                X.append(list(map(int,row)))\n",
    "            elif filePath == \"test.csv\":\n",
    "                X.append(list(map(int,row)))\n",
    "    Y_hot = []\n",
    "    if filePath == \"train.csv\":\n",
    "        Y = np.array(Y)\n",
    "        Y = Y.T\n",
    "        Y_hot = convert_to_one_hot(Y,10)\n",
    "        Y_hot = np.array(Y_hot)\n",
    "        Y_hot = Y_hot.T\n",
    "        Y_hot = Y_hot.reshape((Y_hot.shape[1],Y_hot.shape[2]))\n",
    "    X = np.array(X)\n",
    "    X = X.T\n",
    "    if filePath == \"train.csv\":\n",
    "        return X,Y,Y_hot\n",
    "    return X\n",
    "#this cell contains no mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,Y_train_hot = load_data(\"train.csv\")\n",
    "X_test = load_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(X,Y,batch_size=420):\n",
    "    m = X.shape[1]\n",
    "    batches = []\n",
    "    nb_batches = int(m/batch_size)\n",
    "    \n",
    "    for i in range(0,nb_batches):\n",
    "        current_X = X[:,(i)*batch_size:(i+1)*batch_size-1]\n",
    "        current_Y = Y[:,(i)*batch_size:(i+1)*batch_size-1]\n",
    "        batch = (current_X,current_Y)\n",
    "        batches.append(batch)\n",
    "    return batches\n",
    "def random_mini_batches(X, Y, mini_batch_size = 420):    \n",
    "    m = X.shape[1]                  \n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 42000)\n",
      "(784, 42000)\n",
      "(784, 28000)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_hot.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = X_test[:,55].reshape((28,28),order='C')\n",
    "plt.imshow(digit, cmap='gray', interpolation='nearest');\n",
    "print(\"The label is: \" + str(Y_train[55]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_tf(layers_dims=[784,15,15,10]):\n",
    "    L = len(layers_dims)\n",
    "    tf.set_random_seed(1)\n",
    "    tf.reset_default_graph()\n",
    "    parameters = {}\n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\"+str(l)] = tf.get_variable(\"W\"+str(l), [layers_dims[l], layers_dims[l-1]],\n",
    "                                                 initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "        parameters[\"b\"+str(l)] = tf.get_variable(\"b\"+str(l),shape= [layers_dims[l],1],\n",
    "                            initializer=tf.zeros_initializer())\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n1,n2):\n",
    "    X = tf.placeholder(tf.float32,(n1,n2))\n",
    "    return X\n",
    "def linear_forward_tf(A_prev,W,b):\n",
    "    Z = tf.add(tf.matmul(W, A_prev), b)\n",
    "    return Z\n",
    "def linear_forward_activation_tf(A_prev,W,b):\n",
    "    Z = linear_forward_tf(A_prev,W,b)\n",
    "    A = tf.nn.relu(Z)\n",
    "    return A\n",
    "def L_model_forward_tf(X,parameters,layer_dims):\n",
    "    X = tf.cast(X,dtype=tf.float32)\n",
    "    L = len(layer_dims)\n",
    "    A_prev = X\n",
    "    Z_final = 0\n",
    "    for l in range(1,L):\n",
    "        W = parameters[\"W\"+str(l)]\n",
    "        b = parameters[\"b\"+str(l)]\n",
    "        if l == L-1:\n",
    "            Z_final = linear_forward_tf(A_prev,W,b)\n",
    "        elif l < L-1:\n",
    "            A_prev = linear_forward_activation_tf(A_prev,W,b)\n",
    "    return Z_final   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z_final, Y):\n",
    "    logits = tf.transpose(Z_final)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_tf(X_train,Y_train_hot,learning_rate = 0.0001,nb_epochs = 2000,\n",
    "                layers_dims=[784,15,15,10],mini_batch_size = 420):\n",
    "    parameters = initialize_parameters_tf(layers_dims)\n",
    "    costs = []\n",
    "    n_x = 784\n",
    "    m = 42000\n",
    "    n_y = 10\n",
    "    X = create_placeholders(n_x,420)\n",
    "    Y = create_placeholders(n_y,420)\n",
    "    Z_final = L_model_forward_tf(X,parameters,layers_dims)\n",
    "    cost = compute_cost(Z_final,Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    seed = 0 \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        nb_mini_batch = int(m/mini_batch_size)\n",
    "        for i in range(nb_epochs):\n",
    "            epoch_cost = 0.                       \n",
    "            num_minibatches = int(m / mini_batch_size)\n",
    "            seed = seed + 1\n",
    "            batches = random_mini_batches(X_train, Y_train_hot, mini_batch_size, seed)\n",
    "\n",
    "            for minibatch in batches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , minibatch_cost = sess.run([train, cost], \n",
    "                                             feed_dict={X: minibatch_X, \n",
    "                                                        Y: minibatch_Y})                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            if i%100 == 0:\n",
    "                print(\"Cost value at iteration \"+str(i)+\"th = \"+str(epoch_cost))\n",
    "            costs.append(epoch_cost)\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')       \n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        parameters_values = sess.run(parameters)\n",
    "    return parameters_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = NN_model_tf(X_train,Y_train_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_placeholders(784,28000)\n",
    "Z_test = L_model_forward_tf(X,parameters,layer_dims)\n",
    "Y_pred = tf.nn.softmax(Z_test,axis=1)\n",
    "with tf.Session() as sess:\n",
    "    Z_test_value = sess.run(Z_test,feed_dict={X:X_test})\n",
    "    Y_test = sess.run(Y_pred,feed_dict={Z_test:Z_test_value})\n",
    "    Y_test = np.array(Y_test)\n",
    "Y_real = np.zeros_like(Y_test)\n",
    "Y_real[np.arange(len(Y_test)), Y_test.argmax(1)] = 1\n",
    "\n",
    "index = 55\n",
    "maxIndex = np.max(Y_real[:,index])\n",
    "digit = X_test[:,index].reshape((28,28),order='C')\n",
    "plt.imshow(digit, cmap='gray', interpolation='nearest');\n",
    "print(\"The label is: \" + str(Y_real[:,index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
